//! Query Optimizer
//!
//! Cost-based query optimization for vector search:
//! - Query plan generation
//! - Cost estimation
//! - Filter pushdown
//! - Index selection
//!
//! # Example
//!
//! ```rust,ignore
//! use needle::optimizer::{QueryOptimizer, QueryPlan};
//!
//! let optimizer = QueryOptimizer::new(&collection);
//!
//! let plan = optimizer.optimize(query_vector, Some(filter), 10)?;
//! println!("Estimated cost: {}", plan.estimated_cost);
//! println!("Strategy: {:?}", plan.strategy);
//! ```

use crate::metadata::Filter;
use crate::CollectionRef;
use serde::{Deserialize, Serialize};
use std::time::Duration;

/// Query execution strategy
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum QueryStrategy {
    /// Full vector scan (for small collections)
    FullScan,
    /// HNSW index search
    HnswSearch,
    /// Pre-filter then search (high selectivity filters)
    FilterFirst,
    /// Search then filter (low selectivity filters)
    SearchFirst,
    /// Parallel filter and search with merge
    Parallel,
    /// Use metadata index for initial candidates
    MetadataIndex,
    /// Hybrid: combine multiple strategies
    Hybrid {
        primary: Box<QueryStrategy>,
        secondary: Box<QueryStrategy>,
    },
}

/// Cost model for query execution
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CostModel {
    /// Cost per distance computation
    pub distance_cost: f64,
    /// Cost per metadata check
    pub filter_cost: f64,
    /// Cost per HNSW hop
    pub hnsw_hop_cost: f64,
    /// Cost per disk read (if applicable)
    pub disk_read_cost: f64,
    /// Base overhead cost
    pub base_cost: f64,
    /// Parallelization benefit factor
    pub parallel_factor: f64,
}

impl Default for CostModel {
    fn default() -> Self {
        Self {
            distance_cost: 1.0,
            filter_cost: 0.1,
            hnsw_hop_cost: 2.0,
            disk_read_cost: 10.0,
            base_cost: 5.0,
            parallel_factor: 0.6,
        }
    }
}

/// Query plan generated by optimizer
#[derive(Debug, Clone)]
pub struct QueryPlan {
    /// Execution strategy
    pub strategy: QueryStrategy,
    /// Estimated cost
    pub estimated_cost: f64,
    /// Estimated candidates to evaluate
    pub estimated_candidates: usize,
    /// Estimated latency in milliseconds
    pub estimated_latency_ms: f64,
    /// Whether to use parallelization
    pub parallel: bool,
    /// Filter selectivity estimate (0-1)
    pub filter_selectivity: Option<f64>,
    /// Optimization hints
    pub hints: Vec<OptimizationHint>,
}

/// Optimization hint
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OptimizationHint {
    pub category: HintCategory,
    pub message: String,
    pub impact: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum HintCategory {
    IndexUsage,
    FilterOptimization,
    MemoryUsage,
    Parallelization,
    CachingOpportunity,
}

/// Query execution statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueryStats {
    /// Actual execution time
    pub execution_time: Duration,
    /// Vectors scanned
    pub vectors_scanned: usize,
    /// Vectors passed filter
    pub vectors_filtered: usize,
    /// Distance computations performed
    pub distance_computations: usize,
    /// HNSW nodes visited
    pub hnsw_nodes_visited: usize,
    /// Cache hits
    pub cache_hits: usize,
    /// Strategy used
    pub strategy_used: QueryStrategy,
}

/// Query optimizer
pub struct QueryOptimizer {
    cost_model: CostModel,
    collection_stats: CollectionStats,
    historical_stats: Vec<QueryStats>,
}

/// Collection statistics for optimization
#[derive(Debug, Clone)]
pub struct CollectionStats {
    pub total_vectors: usize,
    pub dimensions: usize,
    pub has_hnsw_index: bool,
    pub hnsw_m: usize,
    pub hnsw_ef_search: usize,
    pub metadata_cardinality: std::collections::HashMap<String, usize>,
    pub avg_vectors_per_metadata_value: std::collections::HashMap<String, f64>,
}

impl QueryOptimizer {
    /// Create a new optimizer
    pub fn new(stats: CollectionStats) -> Self {
        Self {
            cost_model: CostModel::default(),
            collection_stats: stats,
            historical_stats: Vec::new(),
        }
    }

    /// Create optimizer from collection reference
    pub fn from_collection(collection: &CollectionRef) -> Self {
        let total_vectors = collection.len();
        let dimensions = collection.dimensions().unwrap_or(128);
        let collection_stats = CollectionStats {
            total_vectors,
            dimensions,
            has_hnsw_index: true, // Assume HNSW is always used
            hnsw_m: 16,           // Default
            hnsw_ef_search: 50,   // Default
            metadata_cardinality: std::collections::HashMap::new(),
            avg_vectors_per_metadata_value: std::collections::HashMap::new(),
        };

        Self::new(collection_stats)
    }

    /// Set custom cost model
    pub fn with_cost_model(mut self, model: CostModel) -> Self {
        self.cost_model = model;
        self
    }

    /// Optimize a query and return execution plan
    pub fn optimize(
        &self,
        _query_vector: &[f32],
        filter: Option<&Filter>,
        k: usize,
    ) -> QueryPlan {
        let _total_vectors = self.collection_stats.total_vectors;

        // Estimate filter selectivity
        let selectivity = filter.map(|f| self.estimate_selectivity(f));

        // Generate candidate strategies
        let strategies = self.generate_strategies(filter, selectivity);

        // Evaluate each strategy
        let mut best_plan: Option<QueryPlan> = None;

        for strategy in strategies {
            let plan = self.evaluate_strategy(&strategy, k, selectivity);

            if best_plan.is_none() || plan.estimated_cost < best_plan.as_ref().unwrap().estimated_cost {
                best_plan = Some(plan);
            }
        }

        let mut plan = best_plan.unwrap();

        // Add optimization hints
        plan.hints = self.generate_hints(&plan, filter, k);

        plan
    }

    /// Estimate filter selectivity (fraction of vectors that pass)
    fn estimate_selectivity(&self, filter: &Filter) -> f64 {
        use crate::metadata::FilterOperator;

        match filter {
            Filter::Condition(cond) => {
                match cond.operator {
                    FilterOperator::Eq => {
                        // Estimate based on cardinality
                        if let Some(cardinality) = self.collection_stats.metadata_cardinality.get(&cond.field) {
                            1.0 / (*cardinality as f64).max(1.0)
                        } else {
                            0.1 // Default estimate
                        }
                    }
                    FilterOperator::Ne => 0.9,
                    FilterOperator::Gt | FilterOperator::Gte => 0.5,
                    FilterOperator::Lt | FilterOperator::Lte => 0.5,
                    FilterOperator::In => {
                        if let Some(arr) = cond.value.as_array() {
                            let base = 0.1;
                            (base * arr.len() as f64).min(0.9)
                        } else {
                            0.1
                        }
                    }
                    FilterOperator::NotIn => {
                        if let Some(arr) = cond.value.as_array() {
                            1.0 - (0.1 * arr.len() as f64).min(0.9)
                        } else {
                            0.9
                        }
                    }
                    FilterOperator::Contains => 0.3,
                }
            }
            Filter::And(filters) => {
                filters.iter().map(|f| self.estimate_selectivity(f)).product()
            }
            Filter::Or(filters) => {
                let product: f64 = filters.iter().map(|f| 1.0 - self.estimate_selectivity(f)).product();
                1.0 - product
            }
            Filter::Not(inner) => 1.0 - self.estimate_selectivity(inner),
        }
    }

    fn generate_strategies(&self, filter: Option<&Filter>, selectivity: Option<f64>) -> Vec<QueryStrategy> {
        let mut strategies = Vec::new();
        let total = self.collection_stats.total_vectors;

        // Always consider HNSW if available
        if self.collection_stats.has_hnsw_index {
            strategies.push(QueryStrategy::HnswSearch);
        }

        // For small collections, full scan might be faster
        if total < 1000 {
            strategies.push(QueryStrategy::FullScan);
        }

        // If we have a filter
        if filter.is_some() {
            if let Some(sel) = selectivity {
                if sel < 0.1 {
                    // Highly selective filter - filter first
                    strategies.push(QueryStrategy::FilterFirst);
                } else if sel > 0.5 {
                    // Low selectivity - search first
                    strategies.push(QueryStrategy::SearchFirst);
                } else {
                    // Medium selectivity - try parallel
                    strategies.push(QueryStrategy::Parallel);
                }
            }
        }

        strategies
    }

    #[allow(clippy::only_used_in_recursion)]
    fn evaluate_strategy(
        &self,
        strategy: &QueryStrategy,
        k: usize,
        selectivity: Option<f64>,
    ) -> QueryPlan {
        let total = self.collection_stats.total_vectors;
        let _dims = self.collection_stats.dimensions;

        let (cost, candidates, latency) = match strategy {
            QueryStrategy::FullScan => {
                let distance_ops = total;
                let cost = self.cost_model.base_cost
                    + distance_ops as f64 * self.cost_model.distance_cost;
                let latency = cost * 0.01; // Rough conversion to ms
                (cost, total, latency)
            }
            QueryStrategy::HnswSearch => {
                // HNSW typically visits O(log N) * ef nodes
                let ef = self.collection_stats.hnsw_ef_search;
                let log_n = (total as f64).ln().max(1.0);
                let nodes_visited = (log_n * ef as f64) as usize;
                let cost = self.cost_model.base_cost
                    + nodes_visited as f64 * self.cost_model.hnsw_hop_cost
                    + nodes_visited as f64 * self.cost_model.distance_cost;
                let latency = cost * 0.01;
                (cost, nodes_visited, latency)
            }
            QueryStrategy::FilterFirst => {
                let sel = selectivity.unwrap_or(0.1);
                let filtered_count = (total as f64 * sel) as usize;
                let filter_cost = total as f64 * self.cost_model.filter_cost;
                let search_cost = filtered_count as f64 * self.cost_model.distance_cost;
                let cost = self.cost_model.base_cost + filter_cost + search_cost;
                let latency = cost * 0.01;
                (cost, filtered_count, latency)
            }
            QueryStrategy::SearchFirst => {
                let ef = self.collection_stats.hnsw_ef_search;
                let search_candidates = ef * 2; // Over-fetch
                let hnsw_cost = search_candidates as f64
                    * (self.cost_model.hnsw_hop_cost + self.cost_model.distance_cost);
                let filter_cost = search_candidates as f64 * self.cost_model.filter_cost;
                let cost = self.cost_model.base_cost + hnsw_cost + filter_cost;
                let latency = cost * 0.01;
                (cost, search_candidates, latency)
            }
            QueryStrategy::Parallel => {
                // Parallel execution of filter and search
                let sel = selectivity.unwrap_or(0.5);
                let filter_cost = total as f64 * self.cost_model.filter_cost;
                let search_cost = self.collection_stats.hnsw_ef_search as f64
                    * self.cost_model.hnsw_hop_cost;
                let merge_cost = 10.0;
                // Parallel factor reduces total cost
                let cost = self.cost_model.base_cost
                    + filter_cost.max(search_cost) * self.cost_model.parallel_factor
                    + merge_cost;
                let candidates = (total as f64 * sel) as usize;
                let latency = cost * 0.01;
                (cost, candidates, latency)
            }
            QueryStrategy::MetadataIndex => {
                // Use metadata index for initial filtering
                let sel = selectivity.unwrap_or(0.1);
                let index_lookup_cost = 5.0;
                let candidates = (total as f64 * sel) as usize;
                let search_cost = candidates as f64 * self.cost_model.distance_cost;
                let cost = self.cost_model.base_cost + index_lookup_cost + search_cost;
                let latency = cost * 0.01;
                (cost, candidates, latency)
            }
            QueryStrategy::Hybrid { primary, secondary } => {
                let primary_plan = self.evaluate_strategy(primary, k, selectivity);
                let secondary_plan = self.evaluate_strategy(secondary, k, selectivity);
                let cost = primary_plan.estimated_cost * 0.6 + secondary_plan.estimated_cost * 0.4;
                let candidates = primary_plan.estimated_candidates;
                let latency = cost * 0.01;
                (cost, candidates, latency)
            }
        };

        QueryPlan {
            strategy: strategy.clone(),
            estimated_cost: cost,
            estimated_candidates: candidates,
            estimated_latency_ms: latency,
            parallel: matches!(strategy, QueryStrategy::Parallel),
            filter_selectivity: selectivity,
            hints: Vec::new(),
        }
    }

    fn generate_hints(
        &self,
        plan: &QueryPlan,
        filter: Option<&Filter>,
        k: usize,
    ) -> Vec<OptimizationHint> {
        let mut hints = Vec::new();
        let total = self.collection_stats.total_vectors;

        // Index usage hints
        if !self.collection_stats.has_hnsw_index && total > 10000 {
            hints.push(OptimizationHint {
                category: HintCategory::IndexUsage,
                message: "Consider building HNSW index for faster queries".to_string(),
                impact: 0.8,
            });
        }

        // Filter optimization hints
        if let Some(f) = filter {
            if let Some(sel) = plan.filter_selectivity {
                if sel < 0.01 {
                    hints.push(OptimizationHint {
                        category: HintCategory::FilterOptimization,
                        message: "Highly selective filter - consider metadata index".to_string(),
                        impact: 0.5,
                    });
                }
            }

            // Check for expensive filter patterns
            if self.is_expensive_filter(f) {
                hints.push(OptimizationHint {
                    category: HintCategory::FilterOptimization,
                    message: "Complex filter detected - consider simplifying or indexing".to_string(),
                    impact: 0.3,
                });
            }
        }

        // Memory hints
        if total > 1_000_000 {
            hints.push(OptimizationHint {
                category: HintCategory::MemoryUsage,
                message: "Large collection - consider quantization for memory savings".to_string(),
                impact: 0.4,
            });
        }

        // Parallelization hints
        if total > 100_000 && !plan.parallel {
            hints.push(OptimizationHint {
                category: HintCategory::Parallelization,
                message: "Collection size suggests parallelization could help".to_string(),
                impact: 0.3,
            });
        }

        // Caching hints
        if k <= 10 {
            hints.push(OptimizationHint {
                category: HintCategory::CachingOpportunity,
                message: "Small k - results may benefit from caching".to_string(),
                impact: 0.2,
            });
        }

        hints
    }

    #[allow(clippy::only_used_in_recursion)]
    fn is_expensive_filter(&self, filter: &Filter) -> bool {
        match filter {
            Filter::And(filters) | Filter::Or(filters) => {
                filters.len() > 3 || filters.iter().any(|f| self.is_expensive_filter(f))
            }
            Filter::Not(inner) => self.is_expensive_filter(inner),
            _ => false,
        }
    }

    /// Record query statistics for learning
    pub fn record_stats(&mut self, stats: QueryStats) {
        self.historical_stats.push(stats);

        // Keep only recent stats
        if self.historical_stats.len() > 1000 {
            self.historical_stats.remove(0);
        }
    }

    /// Get average stats for a strategy
    pub fn get_strategy_stats(&self, strategy: &QueryStrategy) -> Option<QueryStats> {
        let matching: Vec<&QueryStats> = self
            .historical_stats
            .iter()
            .filter(|s| &s.strategy_used == strategy)
            .collect();

        if matching.is_empty() {
            return None;
        }

        // Average the stats
        let count = matching.len();
        Some(QueryStats {
            execution_time: Duration::from_nanos(
                (matching.iter().map(|s| s.execution_time.as_nanos()).sum::<u128>() / count as u128) as u64,
            ),
            vectors_scanned: matching.iter().map(|s| s.vectors_scanned).sum::<usize>() / count,
            vectors_filtered: matching.iter().map(|s| s.vectors_filtered).sum::<usize>() / count,
            distance_computations: matching.iter().map(|s| s.distance_computations).sum::<usize>() / count,
            hnsw_nodes_visited: matching.iter().map(|s| s.hnsw_nodes_visited).sum::<usize>() / count,
            cache_hits: matching.iter().map(|s| s.cache_hits).sum::<usize>() / count,
            strategy_used: strategy.clone(),
        })
    }
}

/// Query plan explainer (like EXPLAIN ANALYZE)
pub struct QueryExplainer;

impl QueryExplainer {
    /// Generate human-readable explanation of query plan
    pub fn explain(plan: &QueryPlan) -> String {
        let mut output = String::new();

        output.push_str("=== Query Plan ===\n\n");

        output.push_str(&format!("Strategy: {:?}\n", plan.strategy));
        output.push_str(&format!("Estimated Cost: {:.2}\n", plan.estimated_cost));
        output.push_str(&format!("Estimated Candidates: {}\n", plan.estimated_candidates));
        output.push_str(&format!("Estimated Latency: {:.2}ms\n", plan.estimated_latency_ms));
        output.push_str(&format!("Parallel Execution: {}\n", plan.parallel));

        if let Some(sel) = plan.filter_selectivity {
            output.push_str(&format!("Filter Selectivity: {:.2}%\n", sel * 100.0));
        }

        if !plan.hints.is_empty() {
            output.push_str("\n=== Optimization Hints ===\n\n");
            for hint in &plan.hints {
                output.push_str(&format!(
                    "[{:?}] {} (impact: {:.0}%)\n",
                    hint.category,
                    hint.message,
                    hint.impact * 100.0
                ));
            }
        }

        output
    }

    /// Compare actual vs estimated performance
    pub fn analyze(plan: &QueryPlan, stats: &QueryStats) -> String {
        let mut output = String::new();

        output.push_str("=== Query Analysis ===\n\n");

        output.push_str(&format!("Strategy Used: {:?}\n", stats.strategy_used));
        output.push_str(&format!(
            "Actual Time: {:.2}ms\n",
            stats.execution_time.as_secs_f64() * 1000.0
        ));
        output.push_str(&format!("Estimated Time: {:.2}ms\n", plan.estimated_latency_ms));

        let time_accuracy = if plan.estimated_latency_ms > 0.0 {
            let actual_ms = stats.execution_time.as_secs_f64() * 1000.0;
            (1.0 - (actual_ms - plan.estimated_latency_ms).abs() / actual_ms.max(plan.estimated_latency_ms)) * 100.0
        } else {
            0.0
        };
        output.push_str(&format!("Estimate Accuracy: {:.1}%\n\n", time_accuracy));

        output.push_str(&format!("Vectors Scanned: {}\n", stats.vectors_scanned));
        output.push_str(&format!("Vectors After Filter: {}\n", stats.vectors_filtered));
        output.push_str(&format!("Distance Computations: {}\n", stats.distance_computations));
        output.push_str(&format!("HNSW Nodes Visited: {}\n", stats.hnsw_nodes_visited));
        output.push_str(&format!("Cache Hits: {}\n", stats.cache_hits));

        output
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_stats() -> CollectionStats {
        CollectionStats {
            total_vectors: 100_000,
            dimensions: 384,
            has_hnsw_index: true,
            hnsw_m: 16,
            hnsw_ef_search: 50,
            metadata_cardinality: [("category".to_string(), 10)].into_iter().collect(),
            avg_vectors_per_metadata_value: [("category".to_string(), 10000.0)].into_iter().collect(),
        }
    }

    #[test]
    fn test_optimizer_no_filter() {
        let optimizer = QueryOptimizer::new(create_test_stats());
        let query = vec![0.0; 384];
        let plan = optimizer.optimize(&query, None, 10);

        assert!(plan.estimated_cost > 0.0);
        assert_eq!(plan.strategy, QueryStrategy::HnswSearch);
    }

    #[test]
    fn test_optimizer_with_filter() {
        let optimizer = QueryOptimizer::new(create_test_stats());
        let query = vec![0.0; 384];
        let filter = Filter::eq("category".to_string(), serde_json::json!("tech"));
        let plan = optimizer.optimize(&query, Some(&filter), 10);

        assert!(plan.filter_selectivity.is_some());
    }

    #[test]
    fn test_selectivity_estimation() {
        let optimizer = QueryOptimizer::new(create_test_stats());

        // Equality on indexed field
        let eq_filter = Filter::eq("category".to_string(), serde_json::json!("tech"));
        let sel = optimizer.estimate_selectivity(&eq_filter);
        assert!(sel > 0.0 && sel < 1.0);

        // AND combines selectivities
        let and_filter = Filter::And(vec![
            Filter::eq("category".to_string(), serde_json::json!("tech")),
            Filter::eq("category".to_string(), serde_json::json!("ai")),
        ]);
        let and_sel = optimizer.estimate_selectivity(&and_filter);
        assert!(and_sel < sel); // AND should be more selective
    }

    #[test]
    fn test_small_collection_prefers_scan() {
        let mut stats = create_test_stats();
        stats.total_vectors = 100;

        let optimizer = QueryOptimizer::new(stats);
        let query = vec![0.0; 384];
        let plan = optimizer.optimize(&query, None, 10);

        // For very small collections, might choose FullScan
        assert!(plan.estimated_cost > 0.0);
    }

    #[test]
    fn test_query_explainer() {
        let optimizer = QueryOptimizer::new(create_test_stats());
        let query = vec![0.0; 384];
        let plan = optimizer.optimize(&query, None, 10);

        let explanation = QueryExplainer::explain(&plan);
        assert!(explanation.contains("Strategy"));
        assert!(explanation.contains("Estimated"));
    }

    #[test]
    fn test_hints_generation() {
        let mut stats = create_test_stats();
        stats.total_vectors = 2_000_000; // Large collection

        let optimizer = QueryOptimizer::new(stats);
        let query = vec![0.0; 384];
        let plan = optimizer.optimize(&query, None, 5);

        // Should have hints for large collection
        assert!(!plan.hints.is_empty());
    }
}
